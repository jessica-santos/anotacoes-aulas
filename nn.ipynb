{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica-santos/anotacoes-aulas/blob/master/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGYEB3wu01rh",
        "colab_type": "text"
      },
      "source": [
        "# Redes Neurais Artificiais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "remove_cell"
        ],
        "id": "A8ksqCDU01rj",
        "colab_type": "text"
      },
      "source": [
        "## Preparando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRKKNfl801rk",
        "colab_type": "text"
      },
      "source": [
        "Vamos criar uma rede neural simples para prever *churn* de clientes. \n",
        "\n",
        "Vamos come√ßar pela leitura dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQBGMhka01rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D6e8mbB01ro",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf9c7b9d-5b29-4360-b168-a4182a0f783d"
      },
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZmlsHwT01rt",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2e9f262-b284-4b2e-d5e0-28911c4ae44f"
      },
      "source": [
        "df['Exited'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aCqt05at01rw",
        "colab_type": "code",
        "colab": {},
        "outputId": "623608ec-138e-4463-cbcf-972a078a4052"
      },
      "source": [
        "df['Geography'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     5014\n",
              "Germany    2509\n",
              "Spain      2477\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IyE5ePm01ry",
        "colab_type": "code",
        "colab": {},
        "outputId": "47a6e648-5dc3-4a8e-e561-7e2822837ca3"
      },
      "source": [
        "df['Gender'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Male      5457\n",
              "Female    4543\n",
              "Name: Gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F55WS_t401r1",
        "colab_type": "text"
      },
      "source": [
        "Para este exemplo vamos fazer um tratamento simples dos dados, apenas convertendo as vari√°veis categoricas em dummies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGs6BI9s01r1",
        "colab_type": "code",
        "colab": {},
        "outputId": "1147052c-f628-4dd9-e8cd-d96b1dd4380e"
      },
      "source": [
        "df = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Age', 'Tenure',\n",
              "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
              "       'EstimatedSalary', 'Exited', 'Geography_France', 'Geography_Germany',\n",
              "       'Geography_Spain', 'Gender_Female', 'Gender_Male'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_dg-Si001r5",
        "colab_type": "text"
      },
      "source": [
        "Vamos separar os dados de teste e treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyu-8JLl01r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary', \n",
        "        'Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female']]\n",
        "\n",
        "y = df['Exited']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeBizmWM01r8",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce12b498-fa2c-4e0d-e1b0-65383a26ac6d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X , y, test_size = 0.1)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJrD5LK01r_",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9dd1039-698b-48a3-ceb6-8f37432ae66f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_val = sc.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  after removing the cwd from sys.path.\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G1rFBZZ01sB",
        "colab_type": "text"
      },
      "source": [
        "## Construindo o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-YJYGJs01sC",
        "colab_type": "text"
      },
      "source": [
        "Agora com o dados prontos vamos montar a nossa rede neural. Vamos usar a library [Keras](https://keras.io) rodando em cima do [TensorFlow](https://tensorflow.org/)\n",
        "\n",
        "\n",
        "1. Defini√ß√£o da arquitetura\n",
        "\n",
        "2. Compila√ß√£o\n",
        "\n",
        "3. Treinamento\n",
        "\n",
        "4. Avalia√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyW6ePju01sC",
        "colab_type": "text"
      },
      "source": [
        "### 1. Defini√ß√£o da arquitetura: \n",
        "Definir a arquitetura da rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPVavi-01sD",
        "colab_type": "code",
        "colab": {},
        "outputId": "14bc9f9e-1fc0-4d2a-8e0c-4fe18e48980a"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3vTyK8M01sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    # primeira camada adiciona o shape do input\n",
        "    # adiciona a funcao de ativacao\n",
        "    # quantidade de units (neur√¥nios)\n",
        "    # tamb√©m √© poss√≠vel alterar a inicializacao, bias, entre outros -- https://keras.io/layers/core/\n",
        "    model.add(Dense(units=10, input_dim=12, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    \n",
        "    #Camada de saida com o resultado de 1 classe e a ativa√ß√£o sigmoid -- outras fun√ß√µes de ativa√ß√£o: https://keras.io/activations/\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd61j62S01sI",
        "colab_type": "text"
      },
      "source": [
        "### Vamos entender melhor as fun√ß√µes de ativa√ß√£o:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnut6mXL01sI",
        "colab_type": "text"
      },
      "source": [
        "Em cada neur√¥nio da rede h√° uma fun√ß√£o de ativa√ß√£o, que decide se o neur√¥nio deve ser *ativado*, e transmitir informa√ß√µes para a pr√≥xima camada.\n",
        "\n",
        "![](https://i1.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/02/act.png?w=406)\n",
        "\n",
        "A fun√ß√£o mais comum nas camadas intermedi√°rias √© a relu:\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n",
        "\n",
        "Na camada de sa√≠da a rede precisa nos retornar a probabilidade do cliente fazer o cancelamento.\n",
        "\n",
        "Por ser uma probabilidade (de 0 a 1), n√≥s usamos a fun√ß√£o sigmoid:\n",
        "\n",
        "![as vezes a fun√ß√£o sigm√≥ide √© simplesmente representada pela curva S](https://sabedoriararefeita.files.wordpress.com/2016/02/ann_sigmoid.png?w=615)\n",
        "\n",
        "\n",
        "Outras fun√ß√µes comuns:\n",
        "\n",
        "Softmax -> Usada na camada de output para problemas de multiclasse, a soma das probabilidades de todas as classes dar√° 1.\n",
        "\n",
        "elu -> para ser usada nas camadas intermediarias no lugar da relu, uma exponencial √© aplicada nos valores menores que 0.\n",
        "\n",
        "> Em regress√£o n√£o h√° fun√ß√£o de ativa√ß√£o na camada de output\n",
        "\n",
        "outras fun√ß√µes de ativa√ß√£o: https://keras.io/activations/\n",
        "explica√ß√µes extras: http://deeplearningbook.com.br/funcao-de-ativacao/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqBxWWSX01sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R2-4sNUG01sL",
        "colab_type": "code",
        "colab": {},
        "outputId": "0736e091-b74e-4911-fdcf-b952616bca47"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                130       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 251\n",
            "Trainable params: 251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F6w5JCt01sP",
        "colab_type": "text"
      },
      "source": [
        "> Podemos ver que na primeira camada 130 par√¢metros (pesos) ser√£o aprendidos ((12 inputs x 10 layers) + (1 bias * 10 layers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGR3b2Sw01sP",
        "colab_type": "text"
      },
      "source": [
        "### 2. Compilar o modelo:\n",
        "\n",
        "Definer como a rede ir√° aprender. Qual o otimizador com os par√¢metros de learning rate, fun√ß√£o e parametros espec√≠ficos da fun√ß√£o e a loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_XHomw-01sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outras fun√ß√µes de loss: https://keras.io/losses/\n",
        "# outros optimizers: https://keras.io/optimizers/\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xuR3OIU01sT",
        "colab_type": "text"
      },
      "source": [
        "### Vamos entender como a rede aprende:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDh89q001sU",
        "colab_type": "text"
      },
      "source": [
        "Para aprender os par√¢metros $w$ e $b$ √© preciso uma **fun√ß√£o de custo**. Primeiro, vamos definir uma fun√ß√£o de perda ou $Loss Function$ de modo que quanto mais pr√≥ximo da resposta certa, menor seja o valor dessa fun√ß√£o:\n",
        "\n",
        "$L(\\hat{y},y)=-(y\\log{\\hat{y}} + (1-y)\\log{(1-\\hat{y})})$ (binary_crossentropy)\n",
        "\n",
        "> Se uma inst√¢ncia tem label 1, ent√£o $(1-y)$ √© $0$, deixando apenas o lado esquerdo da equa√ß√£o. Pra que ele seja o menor poss√≠vel, $\\hat{y}$ precisa ser o maior poss√≠vel, no caso o mais pr√≥ximo de 1. O oposto tamb√©m se aplica para quando o label √© 0.\n",
        "\n",
        "Com isso, temos a func√£o de custo:\n",
        "\n",
        "$J(w,b)=\\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}^i,y^i)$\n",
        "\n",
        "Dado nosso custo, queremos encontrar $w$ e $b$ que minimize esse custo. Para isso utilizamos o **Gradiente Descendente**. A fun√ß√£o de custo √© uma func√£o convexa, como uma bacia, ent√£o o que o gradiente faz √© ir descendo o mais r√°pido poss√≠vel at√© chegar no fundo da bacia, no menor ponto, independente do ponto inicial.\n",
        "\n",
        "![enter image description here](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)\n",
        "\n",
        "Para fazer essa \"decida\", utilizaremos a derivada do custo e uma taxa de aprendizado ou *learning rate*, da seguinte forma:\n",
        "\n",
        "A cada itera√ß√£o do algoritmo temos $w = w - \\alpha \\frac{\\mathrm{d}J}{\\mathrm{d}w}$, sendo $\\alpha$ o learning rate.\n",
        "\n",
        "De modo geral, atualizamos w e b a cada itera√ß√£o, sendo a velocidade controlada pelo learning rate, at√© chegarmos no ponto m√≠nimo de custo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4RwH9Jb01sV",
        "colab_type": "text"
      },
      "source": [
        "**Mas o que √© o Adam ent√£o?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTnbH0jp01sX",
        "colab_type": "text"
      },
      "source": [
        "Algoritmo de otimiza√ß√£o da taxa de aprendizado adapt√°vel que foi projetado especificamente para o treinamento de redes neurais profundas, pode ser usado em vez do procedimento cl√°ssico de descida de gradiente estoc√°stico (SGD) para atualizar os pesos da rede de forma iterativa com base nos dados de treinamento.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "Mais informa√ß√µes: [artigo original](https://arxiv.org/abs/1412.6980), [post explicativo](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c), [outros otimizadores](http://ruder.io/optimizing-gradient-descent/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKEsEXn401sX",
        "colab_type": "text"
      },
      "source": [
        "> **Importante**: quando estiverem fazendo experimentos com NN, testem com SGD e Adam e com diferentes **LEARNING RATES**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwITCmDi01sY",
        "colab_type": "text"
      },
      "source": [
        "### 3. Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyxaBoNB01sZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "24810f52-845e-478f-ca57-6c6c95738aa1"
      },
      "source": [
        "model.fit(x=X_train, y=y_train, validation_data=(X_val,y_val), batch_size=16, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "9000/9000 [==============================] - 1s 98us/step - loss: 0.4033 - acc: 0.8283 - val_loss: 0.3512 - val_acc: 0.8580\n",
            "Epoch 2/10\n",
            "9000/9000 [==============================] - 1s 84us/step - loss: 0.3544 - acc: 0.8537 - val_loss: 0.3546 - val_acc: 0.8450\n",
            "Epoch 3/10\n",
            "9000/9000 [==============================] - 1s 107us/step - loss: 0.3478 - acc: 0.8562 - val_loss: 0.3370 - val_acc: 0.8630\n",
            "Epoch 4/10\n",
            "9000/9000 [==============================] - 1s 84us/step - loss: 0.3451 - acc: 0.8571 - val_loss: 0.3502 - val_acc: 0.8480\n",
            "Epoch 5/10\n",
            "9000/9000 [==============================] - 1s 77us/step - loss: 0.3436 - acc: 0.8594 - val_loss: 0.3442 - val_acc: 0.8630\n",
            "Epoch 6/10\n",
            "9000/9000 [==============================] - 1s 110us/step - loss: 0.3402 - acc: 0.8601 - val_loss: 0.3433 - val_acc: 0.8570\n",
            "Epoch 7/10\n",
            "9000/9000 [==============================] - 2s 198us/step - loss: 0.3395 - acc: 0.8600 - val_loss: 0.3413 - val_acc: 0.8610\n",
            "Epoch 8/10\n",
            "9000/9000 [==============================] - 2s 182us/step - loss: 0.3399 - acc: 0.8620 - val_loss: 0.3326 - val_acc: 0.8590\n",
            "Epoch 9/10\n",
            "9000/9000 [==============================] - 2s 197us/step - loss: 0.3383 - acc: 0.8609 - val_loss: 0.3301 - val_acc: 0.8620\n",
            "Epoch 10/10\n",
            "9000/9000 [==============================] - 1s 101us/step - loss: 0.3397 - acc: 0.8614 - val_loss: 0.3328 - val_acc: 0.8640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a44f14a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhYl1kcL01sb",
        "colab_type": "text"
      },
      "source": [
        "> Percebemos que s√≥ com 10 √©pocas a rede ainda n√£o tinha convergido, o loss ainda estava caindo, ent√£o poder√≠amos treinar por mais √©pocas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQGY_Rjt01sb",
        "colab_type": "text"
      },
      "source": [
        "Temos dois par√¢metros importantes no treinamento:\n",
        "- N√∫mero de √©pocas: Quantas vezes a rede vai passar por todos as inst√¢ncias\n",
        "- Tamanho do batch: Qual o tamanho do bloco que ela vai usar, ou seja, quantas inst√¢ncias por vez passar√£o pela rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOFC_EIE01sb",
        "colab_type": "text"
      },
      "source": [
        "### 4. Avalia√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usQeizWV01sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r67tho6C01sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSurd8ry01sg",
        "colab_type": "code",
        "colab": {},
        "outputId": "c0e58c3f-79c3-4766-aeee-4113d9eb9e34"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtobs9R401si",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d1cd2c0-6750-49bb-fbc3-f56e41a90688"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[798  13]\n",
            " [104  85]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zof3PBhF01sk",
        "colab_type": "text"
      },
      "source": [
        "## Por que o crescimento de Deep Learning?\n",
        "\n",
        "<img src=\"https://kevinzakka.github.io/assets/app_dl/perf_vs_data.png\" alt=\"drawing\" width=\"600\"/>\n",
        "\n",
        "Algoritmos tradicionais tendem a estabilizar a performance apartir de uma certa quantidade de dados, enquanto redes neurais tendem a ficar cada vez melhores quanto mais dados s√£o utilizados para o aprendizado.\n",
        "\n",
        "Portanto, o principal motivo que faz com que as NN cres√ßam nos √∫ltimos anos √© o grande aumento na quantidade de **dados** dispon√≠veis.  Al√©m disso, o poder **computacional** tamb√©m √© muito maior nos dias atuais, principalmente com a utiliza√ß√£o de GPU's. O que tamb√©m permitiu o desenvolvimento de **algoritmos** mais complexos e potentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfkXMpe601sl",
        "colab_type": "text"
      },
      "source": [
        "Neural Networks, mais especificamente Deep Learning, tem grande aplica√ß√µes em datas n√£o-estruturados, como: Imagens, A√∫dios e Textos."
      ]
    }
  ]
}