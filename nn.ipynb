{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica-santos/anotacoes-aulas/blob/master/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGYEB3wu01rh",
        "colab_type": "text"
      },
      "source": [
        "# Redes Neurais Artificiais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "remove_cell"
        ],
        "id": "A8ksqCDU01rj",
        "colab_type": "text"
      },
      "source": [
        "## Preparando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRKKNfl801rk",
        "colab_type": "text"
      },
      "source": [
        "Vamos criar uma rede neural simples para prever *churn* de clientes. \n",
        "\n",
        "Vamos começar pela leitura dos dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQBGMhka01rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D6e8mbB01ro",
        "colab_type": "code",
        "colab": {},
        "outputId": "cf9c7b9d-5b29-4360-b168-a4182a0f783d"
      },
      "source": [
        "df = pd.read_csv('Churn_Modelling.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZmlsHwT01rt",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2e9f262-b284-4b2e-d5e0-28911c4ae44f"
      },
      "source": [
        "df['Exited'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aCqt05at01rw",
        "colab_type": "code",
        "colab": {},
        "outputId": "623608ec-138e-4463-cbcf-972a078a4052"
      },
      "source": [
        "df['Geography'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     5014\n",
              "Germany    2509\n",
              "Spain      2477\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IyE5ePm01ry",
        "colab_type": "code",
        "colab": {},
        "outputId": "47a6e648-5dc3-4a8e-e561-7e2822837ca3"
      },
      "source": [
        "df['Gender'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Male      5457\n",
              "Female    4543\n",
              "Name: Gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F55WS_t401r1",
        "colab_type": "text"
      },
      "source": [
        "Para este exemplo vamos fazer um tratamento simples dos dados, apenas convertendo as variáveis categoricas em dummies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGs6BI9s01r1",
        "colab_type": "code",
        "colab": {},
        "outputId": "1147052c-f628-4dd9-e8cd-d96b1dd4380e"
      },
      "source": [
        "df = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Age', 'Tenure',\n",
              "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
              "       'EstimatedSalary', 'Exited', 'Geography_France', 'Geography_Germany',\n",
              "       'Geography_Spain', 'Gender_Female', 'Gender_Male'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_dg-Si001r5",
        "colab_type": "text"
      },
      "source": [
        "Vamos separar os dados de teste e treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyu-8JLl01r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary', \n",
        "        'Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female']]\n",
        "\n",
        "y = df['Exited']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeBizmWM01r8",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce12b498-fa2c-4e0d-e1b0-65383a26ac6d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size = 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X , y, test_size = 0.1)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJrD5LK01r_",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9dd1039-698b-48a3-ceb6-8f37432ae66f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_val = sc.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  after removing the cwd from sys.path.\n",
            "/home/jessica/workspace/apresentacoes/venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G1rFBZZ01sB",
        "colab_type": "text"
      },
      "source": [
        "## Construindo o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-YJYGJs01sC",
        "colab_type": "text"
      },
      "source": [
        "Agora com o dados prontos vamos montar a nossa rede neural. Vamos usar a library [Keras](https://keras.io) rodando em cima do [TensorFlow](https://tensorflow.org/)\n",
        "\n",
        "\n",
        "1. Definição da arquitetura\n",
        "\n",
        "2. Compilação\n",
        "\n",
        "3. Treinamento\n",
        "\n",
        "4. Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyW6ePju01sC",
        "colab_type": "text"
      },
      "source": [
        "### 1. Definição da arquitetura: \n",
        "Definir a arquitetura da rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPVavi-01sD",
        "colab_type": "code",
        "colab": {},
        "outputId": "14bc9f9e-1fc0-4d2a-8e0c-4fe18e48980a"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3vTyK8M01sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    # primeira camada adiciona o shape do input\n",
        "    # adiciona a funcao de ativacao\n",
        "    # quantidade de units (neurônios)\n",
        "    # também é possível alterar a inicializacao, bias, entre outros -- https://keras.io/layers/core/\n",
        "    model.add(Dense(units=10, input_dim=12, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    \n",
        "    #Camada de saida com o resultado de 1 classe e a ativação sigmoid -- outras funções de ativação: https://keras.io/activations/\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd61j62S01sI",
        "colab_type": "text"
      },
      "source": [
        "### Vamos entender melhor as funções de ativação:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnut6mXL01sI",
        "colab_type": "text"
      },
      "source": [
        "Em cada neurônio da rede há uma função de ativação, que decide se o neurônio deve ser *ativado*, e transmitir informações para a próxima camada.\n",
        "\n",
        "![](https://i1.wp.com/deeplearningbook.com.br/wp-content/uploads/2018/02/act.png?w=406)\n",
        "\n",
        "A função mais comum nas camadas intermediárias é a relu:\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n",
        "\n",
        "Na camada de saída a rede precisa nos retornar a probabilidade do cliente fazer o cancelamento.\n",
        "\n",
        "Por ser uma probabilidade (de 0 a 1), nós usamos a função sigmoid:\n",
        "\n",
        "![as vezes a função sigmóide é simplesmente representada pela curva S](https://sabedoriararefeita.files.wordpress.com/2016/02/ann_sigmoid.png?w=615)\n",
        "\n",
        "\n",
        "Outras funções comuns:\n",
        "\n",
        "Softmax -> Usada na camada de output para problemas de multiclasse, a soma das probabilidades de todas as classes dará 1.\n",
        "\n",
        "elu -> para ser usada nas camadas intermediarias no lugar da relu, uma exponencial é aplicada nos valores menores que 0.\n",
        "\n",
        "> Em regressão não há função de ativação na camada de output\n",
        "\n",
        "outras funções de ativação: https://keras.io/activations/\n",
        "explicações extras: http://deeplearningbook.com.br/funcao-de-ativacao/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqBxWWSX01sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R2-4sNUG01sL",
        "colab_type": "code",
        "colab": {},
        "outputId": "0736e091-b74e-4911-fdcf-b952616bca47"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                130       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 251\n",
            "Trainable params: 251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F6w5JCt01sP",
        "colab_type": "text"
      },
      "source": [
        "> Podemos ver que na primeira camada 130 parâmetros (pesos) serão aprendidos ((12 inputs x 10 layers) + (1 bias * 10 layers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGR3b2Sw01sP",
        "colab_type": "text"
      },
      "source": [
        "### 2. Compilar o modelo:\n",
        "\n",
        "Definer como a rede irá aprender. Qual o otimizador com os parâmetros de learning rate, função e parametros específicos da função e a loss function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_XHomw-01sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outras funções de loss: https://keras.io/losses/\n",
        "# outros optimizers: https://keras.io/optimizers/\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer=adam,\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xuR3OIU01sT",
        "colab_type": "text"
      },
      "source": [
        "### Vamos entender como a rede aprende:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDh89q001sU",
        "colab_type": "text"
      },
      "source": [
        "Para aprender os parâmetros $w$ e $b$ é preciso uma **função de custo**. Primeiro, vamos definir uma função de perda ou $Loss Function$ de modo que quanto mais próximo da resposta certa, menor seja o valor dessa função:\n",
        "\n",
        "$L(\\hat{y},y)=-(y\\log{\\hat{y}} + (1-y)\\log{(1-\\hat{y})})$ (binary_crossentropy)\n",
        "\n",
        "> Se uma instância tem label 1, então $(1-y)$ é $0$, deixando apenas o lado esquerdo da equação. Pra que ele seja o menor possível, $\\hat{y}$ precisa ser o maior possível, no caso o mais próximo de 1. O oposto também se aplica para quando o label é 0.\n",
        "\n",
        "Com isso, temos a funcão de custo:\n",
        "\n",
        "$J(w,b)=\\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}^i,y^i)$\n",
        "\n",
        "Dado nosso custo, queremos encontrar $w$ e $b$ que minimize esse custo. Para isso utilizamos o **Gradiente Descendente**. A função de custo é uma funcão convexa, como uma bacia, então o que o gradiente faz é ir descendo o mais rápido possível até chegar no fundo da bacia, no menor ponto, independente do ponto inicial.\n",
        "\n",
        "![enter image description here](https://blog.paperspace.com/content/images/2018/05/68747470733a2f2f707669676965722e6769746875622e696f2f6d656469612f696d672f70617274312f6772616469656e745f64657363656e742e676966.gif)\n",
        "\n",
        "Para fazer essa \"decida\", utilizaremos a derivada do custo e uma taxa de aprendizado ou *learning rate*, da seguinte forma:\n",
        "\n",
        "A cada iteração do algoritmo temos $w = w - \\alpha \\frac{\\mathrm{d}J}{\\mathrm{d}w}$, sendo $\\alpha$ o learning rate.\n",
        "\n",
        "De modo geral, atualizamos w e b a cada iteração, sendo a velocidade controlada pelo learning rate, até chegarmos no ponto mínimo de custo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4RwH9Jb01sV",
        "colab_type": "text"
      },
      "source": [
        "**Mas o que é o Adam então?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTnbH0jp01sX",
        "colab_type": "text"
      },
      "source": [
        "Algoritmo de otimização da taxa de aprendizado adaptável que foi projetado especificamente para o treinamento de redes neurais profundas, pode ser usado em vez do procedimento clássico de descida de gradiente estocástico (SGD) para atualizar os pesos da rede de forma iterativa com base nos dados de treinamento.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "Mais informações: [artigo original](https://arxiv.org/abs/1412.6980), [post explicativo](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c), [outros otimizadores](http://ruder.io/optimizing-gradient-descent/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKEsEXn401sX",
        "colab_type": "text"
      },
      "source": [
        "> **Importante**: quando estiverem fazendo experimentos com NN, testem com SGD e Adam e com diferentes **LEARNING RATES**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwITCmDi01sY",
        "colab_type": "text"
      },
      "source": [
        "### 3. Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyxaBoNB01sZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "24810f52-845e-478f-ca57-6c6c95738aa1"
      },
      "source": [
        "model.fit(x=X_train, y=y_train, validation_data=(X_val,y_val), batch_size=16, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "9000/9000 [==============================] - 1s 98us/step - loss: 0.4033 - acc: 0.8283 - val_loss: 0.3512 - val_acc: 0.8580\n",
            "Epoch 2/10\n",
            "9000/9000 [==============================] - 1s 84us/step - loss: 0.3544 - acc: 0.8537 - val_loss: 0.3546 - val_acc: 0.8450\n",
            "Epoch 3/10\n",
            "9000/9000 [==============================] - 1s 107us/step - loss: 0.3478 - acc: 0.8562 - val_loss: 0.3370 - val_acc: 0.8630\n",
            "Epoch 4/10\n",
            "9000/9000 [==============================] - 1s 84us/step - loss: 0.3451 - acc: 0.8571 - val_loss: 0.3502 - val_acc: 0.8480\n",
            "Epoch 5/10\n",
            "9000/9000 [==============================] - 1s 77us/step - loss: 0.3436 - acc: 0.8594 - val_loss: 0.3442 - val_acc: 0.8630\n",
            "Epoch 6/10\n",
            "9000/9000 [==============================] - 1s 110us/step - loss: 0.3402 - acc: 0.8601 - val_loss: 0.3433 - val_acc: 0.8570\n",
            "Epoch 7/10\n",
            "9000/9000 [==============================] - 2s 198us/step - loss: 0.3395 - acc: 0.8600 - val_loss: 0.3413 - val_acc: 0.8610\n",
            "Epoch 8/10\n",
            "9000/9000 [==============================] - 2s 182us/step - loss: 0.3399 - acc: 0.8620 - val_loss: 0.3326 - val_acc: 0.8590\n",
            "Epoch 9/10\n",
            "9000/9000 [==============================] - 2s 197us/step - loss: 0.3383 - acc: 0.8609 - val_loss: 0.3301 - val_acc: 0.8620\n",
            "Epoch 10/10\n",
            "9000/9000 [==============================] - 1s 101us/step - loss: 0.3397 - acc: 0.8614 - val_loss: 0.3328 - val_acc: 0.8640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a44f14a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhYl1kcL01sb",
        "colab_type": "text"
      },
      "source": [
        "> Percebemos que só com 10 épocas a rede ainda não tinha convergido, o loss ainda estava caindo, então poderíamos treinar por mais épocas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQGY_Rjt01sb",
        "colab_type": "text"
      },
      "source": [
        "Temos dois parâmetros importantes no treinamento:\n",
        "- Número de épocas: Quantas vezes a rede vai passar por todos as instâncias\n",
        "- Tamanho do batch: Qual o tamanho do bloco que ela vai usar, ou seja, quantas instâncias por vez passarão pela rede\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOFC_EIE01sb",
        "colab_type": "text"
      },
      "source": [
        "### 4. Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usQeizWV01sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r67tho6C01sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSurd8ry01sg",
        "colab_type": "code",
        "colab": {},
        "outputId": "c0e58c3f-79c3-4766-aeee-4113d9eb9e34"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtobs9R401si",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d1cd2c0-6750-49bb-fbc3-f56e41a90688"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[798  13]\n",
            " [104  85]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zof3PBhF01sk",
        "colab_type": "text"
      },
      "source": [
        "## Por que o crescimento de Deep Learning?\n",
        "\n",
        "<img src=\"https://kevinzakka.github.io/assets/app_dl/perf_vs_data.png\" alt=\"drawing\" width=\"600\"/>\n",
        "\n",
        "Algoritmos tradicionais tendem a estabilizar a performance apartir de uma certa quantidade de dados, enquanto redes neurais tendem a ficar cada vez melhores quanto mais dados são utilizados para o aprendizado.\n",
        "\n",
        "Portanto, o principal motivo que faz com que as NN cresçam nos últimos anos é o grande aumento na quantidade de **dados** disponíveis.  Além disso, o poder **computacional** também é muito maior nos dias atuais, principalmente com a utilização de GPU's. O que também permitiu o desenvolvimento de **algoritmos** mais complexos e potentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfkXMpe601sl",
        "colab_type": "text"
      },
      "source": [
        "Neural Networks, mais especificamente Deep Learning, tem grande aplicações em datas não-estruturados, como: Imagens, Aúdios e Textos."
      ]
    }
  ]
}